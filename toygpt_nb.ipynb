{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDNINaaPLsKH"
      },
      "source": [
        "# toy-gpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A6UeTv-LsKK"
      },
      "source": [
        "in this notebook,\n",
        "- i have done some VERY BASIC data pre processing\n",
        "- trained the model (using cloud gpus)\n",
        "- create output from the model in another file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RkD_v9jLsKK"
      },
      "source": [
        "### some data pre processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded file\n",
        "filename = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "NWivpJrqMdOW",
        "outputId": "34ab6f19-381a-4cf0-a439-4cff726ffb01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-934c844c-2b66-4fb6-8000-022b7c435208\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-934c844c-2b66-4fb6-8000-022b7c435208\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gita.txt to gita.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CaFLPJpLsKK"
      },
      "source": [
        ">***removing the linespaces***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRMof5XHLsKL"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "with open('gita.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Remove empty lines and join text\n",
        "cleaned_text = '\\n'.join(line for line in text.splitlines() if line.strip())\n",
        "\n",
        "# Write back to file\n",
        "with open('gita.txt', 'w') as f:\n",
        "    f.write(cleaned_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWlxi2IBLsKM"
      },
      "source": [
        ">***removing some repititive words***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQFLeNbeLsKM"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "with open('gita.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Remove the specified phrases\n",
        "text = text.replace(\"International Gita Society\", \"\")\n",
        "text = text.replace(\"Bhagavad-Gita\", \"\")\n",
        "\n",
        "# Write back to file\n",
        "with open('gita.txt', 'w') as f:\n",
        "    f.write(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAZp4g8fLsKM"
      },
      "source": [
        "### training and output generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTcuWEquLsKM"
      },
      "source": [
        ">***training the model in notebook environment with help of KAGGLE***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkYlGnuuLsKN",
        "outputId": "c2c2d1f5-4189-48f9-d363-e64e58c37aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.212309 M parameters\n",
            "step 0: train loss 4.5687, val loss 4.5518\n",
            "step 100: train loss 2.7473, val loss 2.7228\n",
            "step 200: train loss 2.5752, val loss 2.5408\n",
            "step 300: train loss 2.4820, val loss 2.4501\n",
            "step 400: train loss 2.3929, val loss 2.3501\n",
            "step 500: train loss 2.3212, val loss 2.2819\n",
            "step 600: train loss 2.2452, val loss 2.1944\n",
            "step 700: train loss 2.1790, val loss 2.1401\n",
            "step 800: train loss 2.1313, val loss 2.0772\n",
            "step 900: train loss 2.0897, val loss 2.0225\n",
            "step 1000: train loss 2.0512, val loss 1.9940\n",
            "step 1100: train loss 2.0031, val loss 1.9568\n",
            "step 1200: train loss 1.9705, val loss 1.9221\n",
            "step 1300: train loss 1.9398, val loss 1.8903\n",
            "step 1400: train loss 1.9138, val loss 1.8420\n",
            "step 1500: train loss 1.8814, val loss 1.8254\n",
            "step 1600: train loss 1.8613, val loss 1.8200\n",
            "step 1700: train loss 1.8264, val loss 1.7893\n",
            "step 1800: train loss 1.8330, val loss 1.7955\n",
            "step 1900: train loss 1.7967, val loss 1.7415\n",
            "step 2000: train loss 1.8009, val loss 1.7663\n",
            "step 2100: train loss 1.7745, val loss 1.7238\n",
            "step 2200: train loss 1.7602, val loss 1.7264\n",
            "step 2300: train loss 1.7384, val loss 1.7065\n",
            "step 2400: train loss 1.7176, val loss 1.6955\n",
            "step 2500: train loss 1.7092, val loss 1.6888\n",
            "step 2600: train loss 1.7051, val loss 1.6794\n",
            "step 2700: train loss 1.6879, val loss 1.6702\n",
            "step 2800: train loss 1.6919, val loss 1.6707\n",
            "step 2900: train loss 1.6700, val loss 1.6387\n",
            "step 3000: train loss 1.6762, val loss 1.6575\n",
            "step 3100: train loss 1.6681, val loss 1.6265\n",
            "step 3200: train loss 1.6551, val loss 1.6366\n",
            "step 3300: train loss 1.6453, val loss 1.6230\n",
            "step 3400: train loss 1.6222, val loss 1.6120\n",
            "step 3500: train loss 1.6439, val loss 1.6350\n",
            "step 3600: train loss 1.6294, val loss 1.6066\n",
            "step 3700: train loss 1.6176, val loss 1.5988\n",
            "step 3800: train loss 1.5990, val loss 1.6027\n",
            "step 3900: train loss 1.6001, val loss 1.5960\n",
            "step 4000: train loss 1.6029, val loss 1.5925\n",
            "step 4100: train loss 1.5881, val loss 1.5922\n",
            "step 4200: train loss 1.5962, val loss 1.5857\n",
            "step 4300: train loss 1.5886, val loss 1.5691\n",
            "step 4400: train loss 1.5718, val loss 1.5948\n",
            "step 4500: train loss 1.5682, val loss 1.5762\n",
            "step 4600: train loss 1.5816, val loss 1.5734\n",
            "step 4700: train loss 1.5580, val loss 1.5755\n",
            "step 4800: train loss 1.5656, val loss 1.5914\n",
            "step 4900: train loss 1.5639, val loss 1.5802\n",
            "step 5000: train loss 1.5515, val loss 1.5567\n",
            "step 5100: train loss 1.5529, val loss 1.5630\n",
            "step 5200: train loss 1.5462, val loss 1.5642\n",
            "step 5300: train loss 1.5447, val loss 1.5536\n",
            "step 5400: train loss 1.5334, val loss 1.5580\n",
            "step 5500: train loss 1.5396, val loss 1.5486\n",
            "step 5600: train loss 1.5345, val loss 1.5629\n",
            "step 5700: train loss 1.5240, val loss 1.5381\n",
            "step 5800: train loss 1.5305, val loss 1.5329\n",
            "step 5900: train loss 1.5315, val loss 1.5468\n",
            "step 6000: train loss 1.5159, val loss 1.5486\n",
            "step 6100: train loss 1.5011, val loss 1.5301\n",
            "step 6200: train loss 1.5248, val loss 1.5434\n",
            "step 6300: train loss 1.5000, val loss 1.5428\n",
            "step 6400: train loss 1.5045, val loss 1.5485\n",
            "step 6500: train loss 1.5049, val loss 1.5323\n",
            "step 6600: train loss 1.5059, val loss 1.5629\n",
            "step 6700: train loss 1.4959, val loss 1.5249\n",
            "step 6800: train loss 1.4942, val loss 1.5333\n",
            "step 6900: train loss 1.4984, val loss 1.5294\n",
            "step 7000: train loss 1.4757, val loss 1.5266\n",
            "step 7100: train loss 1.4712, val loss 1.5156\n",
            "step 7200: train loss 1.4919, val loss 1.5358\n",
            "step 7300: train loss 1.4798, val loss 1.5238\n",
            "step 7400: train loss 1.4758, val loss 1.5168\n",
            "step 7500: train loss 1.4672, val loss 1.5148\n",
            "step 7600: train loss 1.4709, val loss 1.5255\n",
            "step 7700: train loss 1.4861, val loss 1.5163\n",
            "step 7800: train loss 1.4698, val loss 1.5141\n",
            "step 7900: train loss 1.4553, val loss 1.5082\n",
            "step 8000: train loss 1.4465, val loss 1.5062\n",
            "step 8100: train loss 1.4502, val loss 1.5157\n",
            "step 8200: train loss 1.4529, val loss 1.5173\n",
            "step 8300: train loss 1.4487, val loss 1.5075\n",
            "step 8400: train loss 1.4434, val loss 1.5149\n",
            "step 8500: train loss 1.4489, val loss 1.5172\n",
            "step 8600: train loss 1.4541, val loss 1.5236\n",
            "step 8700: train loss 1.4306, val loss 1.5145\n",
            "step 8800: train loss 1.4587, val loss 1.5052\n",
            "step 8900: train loss 1.4393, val loss 1.4959\n",
            "step 9000: train loss 1.4339, val loss 1.5127\n",
            "step 9100: train loss 1.4350, val loss 1.5120\n",
            "step 9200: train loss 1.4306, val loss 1.5186\n",
            "step 9300: train loss 1.4412, val loss 1.5060\n",
            "step 9400: train loss 1.4282, val loss 1.5139\n",
            "step 9500: train loss 1.4362, val loss 1.5197\n",
            "step 9600: train loss 1.4239, val loss 1.4974\n",
            "step 9700: train loss 1.4285, val loss 1.5153\n",
            "step 9800: train loss 1.4255, val loss 1.5117\n",
            "step 9900: train loss 1.4113, val loss 1.4915\n",
            "step 9999: train loss 1.4271, val loss 1.5081\n",
            "\n",
            "my desires furfort., in whamed, Visya’s nowhere\n",
            "Spir perable, ifdent, not life, to Thd to sonslanO\n",
            "Arjuna.\n",
            "Una.\n",
            "This real — He rain it vain noundana, belows the Supreme, rain\n",
            "But First its both nor unitumon ilution-ext\n",
            "Being in all make! through tranquillity, such of thein\n",
            "The givened of Tama frual--give show, rhowr,,\n",
            "and twise (urusing find in the self-knowledging, ar Indiajnorance, foor arge\n",
            "Thou pake. The should deep\n",
            "of charioteed and goodness!--bondage,\n",
            "Which Eternal Being bace; constation of Deludivas,\n",
            "We Lippine thoside, O Klower-Piries,\n",
            "Vopince, and fell being, or and to thee,\n",
            "In fear I all to Impeneth, who are one in the Supreme Being, out the\n",
            "peing the towest very\n",
            "this, nor Heaving trues: I am the modes of the unembentlamp of Arjuna god the ming, and as unglowledge;\n",
            "In when planted on mind and repietion and set for\n",
            "call trive when, those bondress.\n",
            "Whate'er, Soeth that wise Arjuna, \"Dainathfasagivs! as this unciencient,\n",
            "Heav, all Rust; those looking the nut,\n",
            "The limess Self attain, I all mighteousness,\n",
            "And mine of evil your killy lowling,\n",
            "The begion word of Preget--time those aw“t,\n",
            "The power of plain\n",
            "Those whom not, ‘ake To Dhour! I chasimpels modes all goomlith knowed, shain satrifu\n",
            "your many service or spiritual comful heart,\n",
            "The Source warriors, badct, Lord creation of spiritual.\n",
            "Yet, gift, in and is worse worso, and Salt\n",
            "Uplenti's rest and his him kind,\n",
            "Un not toish, and upon Me whose Eternal Being;\n",
            "But Of vention into below. He thy what\n",
            "Worlds him ais More: **2Eternal Being, and purified instows which Me whoils os\n",
            "oncense into thee, quitting the light Ignorance--staudging see\n",
            "With prencient\n",
            "splaid\n",
            "To mindent, all walso ill-deater. This emborn him, majestaining this arress set with one gamen, the fetreed, one’s in materiality and firmered path!\n",
            "Fight, those the divine all waterious wake\n",
            "amomed! I it impen worship will Tudhan;\n",
            "Nhout read brook I am, Iffent. The make a in Am. (12.66-012)\n",
            "Vanareal delive, and perpaced: —\n",
            "Mains not fully king or Men! or\n",
            "self\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import ReLU, functional as F\n",
        "\n",
        "# hyperparameters\n",
        "# ------------\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "epochs = 10000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "\n",
        "with open('gita.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        # Linear transformation for key vectors\n",
        "        self.keys = nn.Linear(n_embd, head_size, bias = False)\n",
        "        # Linear transformation for query vectors\n",
        "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
        "        # Linear transformation for value vectors\n",
        "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
        "        # Create lower triangular matrix for masked attention\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute key, value, query vectors from input\n",
        "        B,T,C = x.shape\n",
        "        k = self.keys(x) #  B,T,C -> Batch, Time(sequence length), Channels\n",
        "        v = self.value(x)\n",
        "        q = self.query(x)\n",
        "\n",
        "        # Compute attention scores/weights\n",
        "        wei = q @ k.transpose(-2,-1) # (B,T,head_size) @ (B,head_size,T) -> (B,T,T)\n",
        "        # Mask future positions\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "        # Apply dropout for regularization\n",
        "        wei = self.dropout(wei)\n",
        "        # Compute weighted sum of values\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "# multi head attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        # Create multiple attention heads in parallel using ModuleList\n",
        "        self.attn = nn.ModuleList([Head(head_size) for _ in range(n_head)])\n",
        "        # Project concatenated outputs back to embedding dimension\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Concatenate outputs from all attention heads\n",
        "        out = torch.cat([attn(x) for attn in self.attn], dim=-1)\n",
        "        # Project back to embedding dimension\n",
        "        out = self.proj(out)\n",
        "        # Apply dropout\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# feed forward\n",
        "class FeedForwardLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.ffwd = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4*n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*n_embd, n_embd),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffwd(x)\n",
        "\n",
        "# transfromer block\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "        self.attn = MultiHeadAttention(num_heads, head_size)\n",
        "        self.ffwd = FeedForwardLayer(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x)) # residual connection\n",
        "        x = x + self.ffwd(self.ln2(x)) # residual connection\n",
        "        return x # B, T, C\n",
        "\n",
        "# gpt\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.embd = nn.Embedding(vocab_size, n_embd)\n",
        "        self.posembd = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(num_heads, head_size) for _ in range(num_layers)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, x, targets=None):  # Add targets argument with default None\n",
        "        embd = self.embd(x)  # (B,T,C)\n",
        "        posembd = self.posembd(torch.arange(x.shape[1], device=x.device))  # Pass token positions\n",
        "        o = embd + posembd\n",
        "        out = self.blocks(o)  # (B ,T ,C)\n",
        "        out = self.ln_f(out)  # (B, T, C)\n",
        "        logits = self.lm_head(out)  # (B, T, vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond) # Call forward with idx_cond\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = GPT(num_heads=n_head,head_size=n_embd // n_head,num_layers = n_layer)\n",
        "m = model.to(device)\n",
        "\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if epoch % eval_interval == 0 or epoch == epochs - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BnY2u7gLsKN"
      },
      "source": [
        ">**saving the outputs of the trained model in the *toygpt_gita_output.txt* file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1xcIfNILsKN",
        "outputId": "151500d3-68c2-442f-9cb8-68458ae166a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text has been saved to toygpt_gita_output\n"
          ]
        }
      ],
      "source": [
        "def save_generated_text(model, output_file='toygpt_gita_output.txt', num_tokens=10000):\n",
        "    # Create starting context (same as in your original code)\n",
        "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "\n",
        "    # Generate the text\n",
        "    generated_indices = model.generate(context, max_new_tokens=num_tokens)[0].tolist()\n",
        "\n",
        "    # Decode the indices to text\n",
        "    generated_text = decode(generated_indices)\n",
        "\n",
        "    # Save to file\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(generated_text)\n",
        "\n",
        "    print(f\"Generated text has been saved to {output_file}\")\n",
        "\n",
        "# Use this function after training the model\n",
        "save_generated_text(m, 'toygpt_gita_output', 10000)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}